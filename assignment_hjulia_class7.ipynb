{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "assignment_hjulia_class7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "rga"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSJl8ZoSucQK"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 7 Assignment: Computer Vision Neural Network**\n",
        "\n",
        "**Student Name: Julia Huang**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-eCUTf6n3BCb"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BHb2ceEO3Qil",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - Pandas dataframe output.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
        "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code == 200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_vNkxmQDucQN"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment you will use YOLO running on Google CoLab.  It is strongly reccomended to run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO.\n",
        "\n",
        "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.\n",
        "\n",
        "You can see a sample of the WebCam here:\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png)\n",
        "\n",
        "YOLO does quite well recognizing objects in this webcam, as the following image illustrates.\n",
        "\n",
        "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
        "\n",
        "You are to write a script that counts the number of certian objects in each of the images.  Specificially, you are looking for:\n",
        "\n",
        "* person\n",
        "* car\n",
        "* bicycle\n",
        "* motorbike\n",
        "* umbrella\n",
        "* handbag\n",
        "\n",
        "Your submit dataframe should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows total.  The complete dataframe should look something like this.\n",
        "\n",
        "|image|person|car|bicycle|motorbike|umbrella|handbag|\n",
        "|-|-|-|-|-|-|-|\n",
        "|1|22|1|2|1|1|0|\n",
        "|2|33|2|4|1|0|1|\n",
        "|3|21|0|0|0|3|0|\n",
        "|...|...|...|...|...|...|...|\n",
        "\n",
        "\n",
        "The following code simply sets up YOLO and then dumps the classification information for the first image.  It is just meant to get you started.  Read in all 10 images and generate a dataframe that looks something like the following. Use the **submit** function like you did in previoius assiignments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gd6z4JBDucQO",
        "outputId": "82a9fa2a-772e-46fa-e180-0f4d8747647c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!git clone https://github.com/thtrieu/darkflow.git\n",
        "!pip install ./darkflow/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darkflow'...\n",
            "remote: Enumerating objects: 2706, done.\u001b[K\n",
            "remote: Total 2706 (delta 0), reused 0 (delta 0), pack-reused 2706\n",
            "Receiving objects: 100% (2706/2706), 32.98 MiB | 36.78 MiB/s, done.\n",
            "Resolving deltas: 100% (1760/1760), done.\n",
            "Processing ./darkflow\n",
            "Building wheels for collected packages: darkflow\n",
            "  Building wheel for darkflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for darkflow: filename=darkflow-1.0.0-cp36-cp36m-linux_x86_64.whl size=831144 sha256=0c089e96220208b822cbe13693b8eca9883672127cf264be7b80d4b8f4e02129\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w7hkcetm/wheels/2f/3a/c5/e84e79d73d5a73aa1b5129a66a40947d9d77a32ebed501e431\n",
            "Successfully built darkflow\n",
            "Installing collected packages: darkflow\n",
            "Successfully installed darkflow-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h-MFjcKau8q5",
        "outputId": "186b9018-9fc9-4754-d135-2f57ebe9a225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZYXTbKD8vLFb",
        "outputId": "419cf8e8-90cd-43a4-b37b-cc94560c13ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# The following helper script will create a projects/yolo folder for you \n",
        "# and download the needed files.  \n",
        "\n",
        "!mkdir -p /content/drive/My\\ Drive/projects\n",
        "!mkdir -p /content/drive/My\\ Drive/projects/yolo\n",
        "!mkdir -p /content/drive/My\\ Drive/projects/yolo/bin\n",
        "!mkdir -p /content/drive/My\\ Drive/projects/yolo/cfg\n",
        "!wget https://raw.githubusercontent.com/thtrieu/darkflow/master/cfg/coco.names -O /content/drive/My\\ Drive/projects/yolo/cfg/coco.names\n",
        "!wget https://raw.githubusercontent.com/thtrieu/darkflow/master/cfg/yolo.cfg -O /content/drive/My\\ Drive/projects/yolo/cfg/yolo.cfg\n",
        "!wget https://pjreddie.com/media/files/yolov2.weights -O /content/drive/My\\ Drive/projects/yolo/bin/yolo.weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-20 23:27:54--  https://raw.githubusercontent.com/thtrieu/darkflow/master/cfg/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘/content/drive/My Drive/projects/yolo/cfg/coco.names’\n",
            "\n",
            "/content/drive/My D 100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-20 23:27:54 (129 MB/s) - ‘/content/drive/My Drive/projects/yolo/cfg/coco.names’ saved [625/625]\n",
            "\n",
            "--2019-10-20 23:27:55--  https://raw.githubusercontent.com/thtrieu/darkflow/master/cfg/yolo.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2726 (2.7K) [text/plain]\n",
            "Saving to: ‘/content/drive/My Drive/projects/yolo/cfg/yolo.cfg’\n",
            "\n",
            "/content/drive/My D 100%[===================>]   2.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-20 23:27:55 (19.0 MB/s) - ‘/content/drive/My Drive/projects/yolo/cfg/yolo.cfg’ saved [2726/2726]\n",
            "\n",
            "--2019-10-20 23:28:01--  https://pjreddie.com/media/files/yolov2.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203934260 (194M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/projects/yolo/bin/yolo.weights’\n",
            "\n",
            "/content/drive/My D 100%[===================>] 194.49M  2.85MB/s    in 88s     \n",
            "\n",
            "2019-10-20 23:29:29 (2.21 MB/s) - ‘/content/drive/My Drive/projects/yolo/bin/yolo.weights’ saved [203934260/203934260]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehrTvSZ3_OzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"Yg3Uc8sn118A6HaWAFSKG5g1Th1nOyw34jLD5Uh8\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "file='/content/drive/My Drive/Colab Notebooks/assignment_hjulia_class7.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class7.ipynb'  # Windows\n",
        "#file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class7.ipynb'  # Mac/Linux"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NKsq0Z1HvWxT",
        "outputId": "ca066d75-1499-4d4e-9c6c-6f8158abecc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from darkflow.net.build import TFNet\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import os\n",
        "from scipy import misc\n",
        "from io import BytesIO\n",
        "from urllib.request import urlopen\n",
        "\n",
        "os.chdir('/content/drive/My Drive/projects/yolo') # Google CoLab\n",
        "#os.chdir('/Users/jheaton/projects/darkflow') # Local\n",
        "\n",
        "# For GPU (Google CoLab)\n",
        "options = {\"model\": \"./cfg/yolo.cfg\", \"load\": \"./bin/yolo.weights\", \"threshold\": 0.1, \"gpu\": 1.0}\n",
        "\n",
        "# For CPU \n",
        "#options = {\"model\": \"./cfg/yolo.cfg\", \"load\": \"./bin/yolo.weights\", \"threshold\": 0.1}\n",
        "\n",
        "tfnet = TFNet(options)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:20: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:21: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:22: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "Parsing ./cfg/yolo.cfg\n",
            "Loading ./bin/yolo.weights ...\n",
            "Successfully identified 203934260 bytes\n",
            "Finished in 0.06534552574157715s\n",
            "Model has a coco model name, loading coco labels.\n",
            "\n",
            "Building net ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/ops/baseop.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/ops/baseop.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/ops/baseop.py:84: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "       |        | input                            | (?, 608, 608, 3)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/ops/simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
            " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/ops/convolution.py:28: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "ksizes is deprecated, use sizes instead\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
            " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
            " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:132: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:145: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:146: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:149: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/darkflow/net/build.py:149: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Finished in 9.180256128311157s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ri4HkaiT8Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ct_obj(result):\n",
        "  ct = {'person':0, 'car':0, 'bicycle':0, 'motorbike':0, 'umbrella':0, 'handbag':0}\n",
        "  \n",
        "  for obj in result:\n",
        "    if obj['label'] not in ct:\n",
        "      pass\n",
        "    else:\n",
        "      ct[obj['label']] += 1\n",
        "  print(obj)\n",
        "  return ct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWrAAG_zATAy",
        "colab_type": "code",
        "outputId": "d7a1530a-e2d8-4f00-d6d0-aba5cafd372f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "images = [\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.png\",\n",
        "    \"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.png\"\n",
        "]\n",
        "\n",
        "df = []\n",
        "\n",
        "# Read image to classify\n",
        "for url in images:\n",
        "  resp = urlopen(url)\n",
        "  img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "\n",
        "  result = tfnet.return_predict(img)\n",
        "  df.append(ct_obj(result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'label': 'suitcase', 'confidence': 0.107784346, 'topleft': {'x': 1287, 'y': 521}, 'bottomright': {'x': 1325, 'y': 581}}\n",
            "{'label': 'suitcase', 'confidence': 0.3202041, 'topleft': {'x': 1253, 'y': 435}, 'bottomright': {'x': 1287, 'y': 489}}\n",
            "{'label': 'orange', 'confidence': 0.22648667, 'topleft': {'x': 1357, 'y': 351}, 'bottomright': {'x': 1461, 'y': 422}}\n",
            "{'label': 'suitcase', 'confidence': 0.2281002, 'topleft': {'x': 1261, 'y': 436}, 'bottomright': {'x': 1300, 'y': 489}}\n",
            "{'label': 'umbrella', 'confidence': 0.30012438, 'topleft': {'x': 16, 'y': 601}, 'bottomright': {'x': 280, 'y': 818}}\n",
            "{'label': 'umbrella', 'confidence': 0.1643294, 'topleft': {'x': 15, 'y': 601}, 'bottomright': {'x': 284, 'y': 802}}\n",
            "{'label': 'umbrella', 'confidence': 0.3025265, 'topleft': {'x': 4, 'y': 609}, 'bottomright': {'x': 289, 'y': 809}}\n",
            "{'label': 'umbrella', 'confidence': 0.41458988, 'topleft': {'x': 3, 'y': 603}, 'bottomright': {'x': 288, 'y': 813}}\n",
            "{'label': 'parking meter', 'confidence': 0.16173144, 'topleft': {'x': 942, 'y': 0}, 'bottomright': {'x': 1095, 'y': 52}}\n",
            "{'label': 'aeroplane', 'confidence': 0.20776768, 'topleft': {'x': 1454, 'y': 210}, 'bottomright': {'x': 1583, 'y': 280}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPOx1mKTU9Jr",
        "colab_type": "code",
        "outputId": "394d948c-84f4-4704-ad14-7e4ed9d37d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "submit_df = pd.DataFrame(df)\n",
        "submit_df['image'] = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "submit_df = submit_df[['image', 'bicycle','car','handbag','motorbike','person','umbrella']]\n",
        "submit_df\n",
        "submit(source_file=file,data=submit_df,key=key,no=7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success: Submitted Assignment #7 for hjulia:\n",
            "This is your first submission of this assignment.\n",
            "No warnings on your data. You will probably do well, but no guarantee. :-)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}