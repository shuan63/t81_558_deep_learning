{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "rga"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "assignment_jhuang_class8.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjfEiCIAjWw-",
        "colab_type": "text"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 8 Assignment: Building a Kaggle Submission File**\n",
        "\n",
        "**Student Name: Julia Huang**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26s2pYjsjWxB",
        "colab_type": "text"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment you will use the [**reg-33-data.csv**](http://data.heatonresearch.com/data/t81-558/datasets/reg-33-data.csv) dataset to train a neural network and [**reg-33-eval.csv**](http://data.heatonresearch.com/data/t81-558/datasets/reg-33-eval.csv) to use as test to build a submission (similar to Kaggle).  The preprocessing/feature engineering code used for this assignment will be identical to [Assignmnent 5](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class5.ipynb) and you are encouraged to use your Assignment 5 code as a starting point.  Refer to [Module 8](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class8_kaggle.ipynb) for instructions on producing a Kaggle type submission file.  \n",
        "\n",
        "The dataframe that you submit should have two columns: *id* and *target*.  The *id* column should matchup with the test data file.  The *target* column is your prediction.  It is unlikely that the mean of *target* will match exactly with mine.\n",
        "\n",
        "Note, my version generated this warning.  You should be lower than 300, obviously, lower is better!  **Warning: The mean of column target differs from the solution file by 121.90476911730366.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFYB4M-njWxC",
        "colab_type": "text"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
        "\n",
        "**It is unlikely that should need to modify this function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXJ0xaejWxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - Pandas dataframe output.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
        "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code == 200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BJlrCbQjWxJ",
        "colab_type": "text"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process.  Running the following code will map your GDrive to /content/drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImJ4nrAHjWxL",
        "colab_type": "code",
        "outputId": "77540fb4-8aa9-4908-e37d-a744e3c70df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mehF84snjWxS",
        "colab_type": "code",
        "outputId": "bcba0c27-66a4-4c85-f62f-81b95c5189c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assignment_hjulia_class7.ipynb\tassignment_jhuang_class6.ipynb\n",
            "assignment_jhuang_class1.ipynb\tassignment_jhuang_class8.ipynb\n",
            "assignment_jhuang_class2.ipynb\tassignment_juliahuang_class3.ipynb\n",
            "assignment_jhuang_class3.ipynb\tUntitled\n",
            "assignment_jhuang_class4.ipynb\tUntitled0.ipynb\n",
            "assignment_jhuang_class5.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "qzAWAyKCjWxU",
        "colab_type": "text"
      },
      "source": [
        "# Assignment #8 Sample Code\n",
        "\n",
        "The following code provides a starting point for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjb4qq64jWxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn import metrics\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"Yg3Uc8sn118A6HaWAFSKG5g1Th1nOyw34jLD5Uh8\"\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "file='/content/drive/My Drive/Colab Notebooks/assignment_jhuang_class8.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class8.ipynb'  # Windows\n",
        "#file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class8.ipynb'  # Mac/Linux\n",
        "\n",
        "# Begin assignment\n",
        "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/reg-33-data.csv\")\n",
        "\n",
        "\n",
        "# Encode the feature vector\n",
        "ids = df['id']\n",
        "df.drop('id',1,inplace=True)\n",
        "\n",
        "# Generate dummies for convention\n",
        "df = pd.concat([df,pd.get_dummies(df['convention'],prefix=\"convention\")],axis=1)\n",
        "df.drop('convention', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for cat2\n",
        "df = pd.concat([df,pd.get_dummies(df['cat2'],prefix=\"cat2\")],axis=1)\n",
        "df.drop('cat2', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for usage\n",
        "df = pd.concat([df,pd.get_dummies(df['usage'],prefix=\"usage\")],axis=1)\n",
        "df.drop('usage', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for region\n",
        "df = pd.concat([df,pd.get_dummies(df['region'],prefix=\"region\")],axis=1)\n",
        "df.drop('region', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for code\n",
        "df = pd.concat([df,pd.get_dummies(df['code'],prefix=\"code\")],axis=1)\n",
        "df.drop('code', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for item\n",
        "df = pd.concat([df,pd.get_dummies(df['item'],prefix=\"item\")],axis=1)\n",
        "df.drop('item', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for usage\n",
        "df = pd.concat([df,pd.get_dummies(df['country'],prefix=\"country\")],axis=1)\n",
        "df.drop('country', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for height\n",
        "med = df['height'].median()\n",
        "df['height'] = df['height'].fillna(med)\n",
        "\n",
        "# Missing values for length\n",
        "med = df['length'].median()\n",
        "df['length'] = df['length'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['height'] = zscore(df['height'])\n",
        "df['max'] = zscore(df['max'])\n",
        "df['number'] = zscore(df['number'])\n",
        "df['length'] = zscore(df['length'])\n",
        "df['power'] = zscore(df['power'])\n",
        "df['weight'] = zscore(df['weight'])\n",
        "\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('target')\n",
        "x = df[x_columns].values\n",
        "y = df['target'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N90OKg6DjWxb",
        "colab_type": "code",
        "outputId": "9d3e77c9-ec9f-45b6-ed4f-f2c2431d2ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(    \n",
        "    x, y, test_size=0.25, random_state=42)\n",
        "    \n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(10, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \n",
        "                        verbose=1, mode='auto', restore_best_weights=True)\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "          verbose=2,callbacks=[monitor],epochs=1000)\n",
        "  \n",
        "# Predict\n",
        "pred = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8106 samples, validate on 2703 samples\n",
            "Epoch 1/1000\n",
            "8106/8106 - 1s - loss: 9414560477.1971 - val_loss: 9324467494.9256\n",
            "Epoch 2/1000\n",
            "8106/8106 - 0s - loss: 9328169142.6677 - val_loss: 9147636510.5912\n",
            "Epoch 3/1000\n",
            "8106/8106 - 0s - loss: 9020320610.8502 - val_loss: 8694988207.1180\n",
            "Epoch 4/1000\n",
            "8106/8106 - 0s - loss: 8403527205.1399 - val_loss: 7913570664.2753\n",
            "Epoch 5/1000\n",
            "8106/8106 - 0s - loss: 7460486135.9151 - val_loss: 6822997009.2371\n",
            "Epoch 6/1000\n",
            "8106/8106 - 0s - loss: 6247232641.8633 - val_loss: 5519071310.6090\n",
            "Epoch 7/1000\n",
            "8106/8106 - 0s - loss: 4890012385.6186 - val_loss: 4147879320.1036\n",
            "Epoch 8/1000\n",
            "8106/8106 - 0s - loss: 3548201337.2415 - val_loss: 2874756837.5760\n",
            "Epoch 9/1000\n",
            "8106/8106 - 0s - loss: 2375533054.8631 - val_loss: 1834349862.4047\n",
            "Epoch 10/1000\n",
            "8106/8106 - 0s - loss: 1482373426.3884 - val_loss: 1106553805.2830\n",
            "Epoch 11/1000\n",
            "8106/8106 - 0s - loss: 902657525.1675 - val_loss: 679409857.7521\n",
            "Epoch 12/1000\n",
            "8106/8106 - 0s - loss: 583309836.5221 - val_loss: 463337881.9327\n",
            "Epoch 13/1000\n",
            "8106/8106 - 0s - loss: 427702993.7646 - val_loss: 362756012.0755\n",
            "Epoch 14/1000\n",
            "8106/8106 - 0s - loss: 350746068.0306 - val_loss: 308608024.6127\n",
            "Epoch 15/1000\n",
            "8106/8106 - 0s - loss: 302901661.4972 - val_loss: 269743952.1953\n",
            "Epoch 16/1000\n",
            "8106/8106 - 0s - loss: 264242487.6151 - val_loss: 235658903.8017\n",
            "Epoch 17/1000\n",
            "8106/8106 - 0s - loss: 229554353.4113 - val_loss: 204492709.4576\n",
            "Epoch 18/1000\n",
            "8106/8106 - 0s - loss: 197510814.3025 - val_loss: 175595906.3322\n",
            "Epoch 19/1000\n",
            "8106/8106 - 0s - loss: 167885223.4730 - val_loss: 148697920.3433\n",
            "Epoch 20/1000\n",
            "8106/8106 - 0s - loss: 140615066.5877 - val_loss: 124195765.5523\n",
            "Epoch 21/1000\n",
            "8106/8106 - 0s - loss: 115766737.7172 - val_loss: 101891225.3822\n",
            "Epoch 22/1000\n",
            "8106/8106 - 0s - loss: 93455027.8253 - val_loss: 81934259.3918\n",
            "Epoch 23/1000\n",
            "8106/8106 - 0s - loss: 73761311.4404 - val_loss: 64386241.1128\n",
            "Epoch 24/1000\n",
            "8106/8106 - 0s - loss: 56857978.5028 - val_loss: 49370194.3589\n",
            "Epoch 25/1000\n",
            "8106/8106 - 0s - loss: 42683828.4106 - val_loss: 36899867.0011\n",
            "Epoch 26/1000\n",
            "8106/8106 - 0s - loss: 31211666.8389 - val_loss: 26859260.2945\n",
            "Epoch 27/1000\n",
            "8106/8106 - 0s - loss: 22290762.1273 - val_loss: 19118701.1628\n",
            "Epoch 28/1000\n",
            "8106/8106 - 0s - loss: 15665147.4525 - val_loss: 13445768.1606\n",
            "Epoch 29/1000\n",
            "8106/8106 - 0s - loss: 10981654.1514 - val_loss: 9458901.0218\n",
            "Epoch 30/1000\n",
            "8106/8106 - 0s - loss: 7872533.5210 - val_loss: 6816388.9737\n",
            "Epoch 31/1000\n",
            "8106/8106 - 0s - loss: 5924212.7555 - val_loss: 5168361.6782\n",
            "Epoch 32/1000\n",
            "8106/8106 - 0s - loss: 4766219.2838 - val_loss: 4196470.4350\n",
            "Epoch 33/1000\n",
            "8106/8106 - 0s - loss: 4120889.8856 - val_loss: 3641773.3352\n",
            "Epoch 34/1000\n",
            "8106/8106 - 0s - loss: 3772863.1010 - val_loss: 3337319.3001\n",
            "Epoch 35/1000\n",
            "8106/8106 - 0s - loss: 3587599.8115 - val_loss: 3175861.2206\n",
            "Epoch 36/1000\n",
            "8106/8106 - 0s - loss: 3491514.5439 - val_loss: 3088534.6067\n",
            "Epoch 37/1000\n",
            "8106/8106 - 0s - loss: 3440181.3717 - val_loss: 3043044.1277\n",
            "Epoch 38/1000\n",
            "8106/8106 - 0s - loss: 3413400.5342 - val_loss: 3020014.2314\n",
            "Epoch 39/1000\n",
            "8106/8106 - 0s - loss: 3401121.1467 - val_loss: 3009265.7295\n",
            "Epoch 40/1000\n",
            "8106/8106 - 0s - loss: 3395536.8727 - val_loss: 3003643.7420\n",
            "Epoch 41/1000\n",
            "8106/8106 - 0s - loss: 3392242.1482 - val_loss: 3001489.8560\n",
            "Epoch 42/1000\n",
            "8106/8106 - 0s - loss: 3391688.8882 - val_loss: 3000491.3881\n",
            "Epoch 43/1000\n",
            "8106/8106 - 0s - loss: 3392077.7099 - val_loss: 2998091.1858\n",
            "Epoch 44/1000\n",
            "8106/8106 - 0s - loss: 3392528.3068 - val_loss: 3001312.8275\n",
            "Epoch 45/1000\n",
            "8106/8106 - 0s - loss: 3393347.8727 - val_loss: 2997560.8638\n",
            "Epoch 46/1000\n",
            "8106/8106 - 0s - loss: 3391767.1967 - val_loss: 2998263.7754\n",
            "Epoch 47/1000\n",
            "8106/8106 - 0s - loss: 3393802.5158 - val_loss: 2998730.1473\n",
            "Epoch 48/1000\n",
            "8106/8106 - 0s - loss: 3393798.7539 - val_loss: 2999413.6796\n",
            "Epoch 49/1000\n",
            "8106/8106 - 0s - loss: 3394531.9703 - val_loss: 2997210.1059\n",
            "Epoch 50/1000\n",
            "8106/8106 - 0s - loss: 3392586.7679 - val_loss: 2997252.1515\n",
            "Epoch 51/1000\n",
            "8106/8106 - 0s - loss: 3391575.5343 - val_loss: 3000315.5440\n",
            "Epoch 52/1000\n",
            "8106/8106 - 0s - loss: 3393139.6812 - val_loss: 2996454.5968\n",
            "Epoch 53/1000\n",
            "8106/8106 - 0s - loss: 3392339.9901 - val_loss: 2996047.7305\n",
            "Epoch 54/1000\n",
            "8106/8106 - 0s - loss: 3392330.7161 - val_loss: 2991486.8994\n",
            "Epoch 55/1000\n",
            "8106/8106 - 0s - loss: 3391536.1467 - val_loss: 3002500.4872\n",
            "Epoch 56/1000\n",
            "8106/8106 - 0s - loss: 3388252.3947 - val_loss: 2991381.0440\n",
            "Epoch 57/1000\n",
            "8106/8106 - 0s - loss: 3389251.8817 - val_loss: 2993003.5361\n",
            "Epoch 58/1000\n",
            "8106/8106 - 0s - loss: 3390209.6937 - val_loss: 2992760.3926\n",
            "Epoch 59/1000\n",
            "8106/8106 - 0s - loss: 3386567.9639 - val_loss: 3030953.0065\n",
            "Epoch 60/1000\n",
            "8106/8106 - 0s - loss: 3389672.3149 - val_loss: 2992066.3633\n",
            "Epoch 61/1000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "8106/8106 - 0s - loss: 3387372.4517 - val_loss: 2998613.5998\n",
            "Epoch 00061: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rq6gqyNn0hE",
        "colab_type": "code",
        "outputId": "c7ef7aff-8672-43a4-e358-bca4fbf8d024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final score (RMSE): 1729.560935683772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRD39FIZrDgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/reg-33-eval.csv\")\n",
        "\n",
        "\n",
        "# Encode the feature vector\n",
        "ids = df['id']\n",
        "df.drop('id',1,inplace=True)\n",
        "\n",
        "# Generate dummies for convention\n",
        "df = pd.concat([df,pd.get_dummies(df['convention'],prefix=\"convention\")],axis=1)\n",
        "df.drop('convention', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for cat2\n",
        "df = pd.concat([df,pd.get_dummies(df['cat2'],prefix=\"cat2\")],axis=1)\n",
        "df.drop('cat2', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for usage\n",
        "df = pd.concat([df,pd.get_dummies(df['usage'],prefix=\"usage\")],axis=1)\n",
        "df.drop('usage', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for region\n",
        "df = pd.concat([df,pd.get_dummies(df['region'],prefix=\"region\")],axis=1)\n",
        "df.drop('region', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for code\n",
        "df = pd.concat([df,pd.get_dummies(df['code'],prefix=\"code\")],axis=1)\n",
        "df.drop('code', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for item\n",
        "df = pd.concat([df,pd.get_dummies(df['item'],prefix=\"item\")],axis=1)\n",
        "df.drop('item', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for usage\n",
        "df = pd.concat([df,pd.get_dummies(df['country'],prefix=\"country\")],axis=1)\n",
        "df.drop('country', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for height\n",
        "med = df['height'].median()\n",
        "df['height'] = df['height'].fillna(med)\n",
        "\n",
        "# Missing values for length\n",
        "med = df['length'].median()\n",
        "df['length'] = df['length'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['height'] = zscore(df['height'])\n",
        "df['max'] = zscore(df['max'])\n",
        "df['number'] = zscore(df['number'])\n",
        "df['length'] = zscore(df['length'])\n",
        "df['power'] = zscore(df['power'])\n",
        "df['weight'] = zscore(df['weight'])\n",
        "\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns\n",
        "x = df[x_columns].values\n",
        "\n",
        "pred = model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux9vkMGvwD7J",
        "colab_type": "code",
        "outputId": "304d0de6-2859-4d93-d0aa-b17112c19cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_submit = pd.DataFrame(pred)\n",
        "df_submit.insert(0,'id',ids)\n",
        "df_submit.columns = ['id','target']\n",
        "\n",
        "df_submit.to_csv(\"reg_submit.csv\", index=False) # Write submit file locally\n",
        "\n",
        "df_submit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10810</td>\n",
              "      <td>74290.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10811</td>\n",
              "      <td>101452.421875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10812</td>\n",
              "      <td>402.904297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10813</td>\n",
              "      <td>42895.277344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10814</td>\n",
              "      <td>41186.191406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>11805</td>\n",
              "      <td>121670.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>11806</td>\n",
              "      <td>88694.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>11807</td>\n",
              "      <td>94123.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>11808</td>\n",
              "      <td>76196.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>11809</td>\n",
              "      <td>170724.140625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id         target\n",
              "0    10810   74290.671875\n",
              "1    10811  101452.421875\n",
              "2    10812     402.904297\n",
              "3    10813   42895.277344\n",
              "4    10814   41186.191406\n",
              "..     ...            ...\n",
              "995  11805  121670.882812\n",
              "996  11806   88694.882812\n",
              "997  11807   94123.062500\n",
              "998  11808   76196.718750\n",
              "999  11809  170724.140625\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}